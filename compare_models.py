"""
PyTorch ëª¨ë¸ê³¼ ONNX ëª¨ë¸ì˜ ì¶”ë¡  ê²°ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import numpy as np
import cv2
from ultralytics import YOLO
from berryModel import YOLOPredictor

def compare_models(image_path: str, pt_model_path: str, onnx_model_path: str):
    """
    PyTorch ëª¨ë¸ê³¼ ONNX ëª¨ë¸ì˜ ì¶”ë¡  ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
    
    Args:
        image_path: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
        pt_model_path: PyTorch ëª¨ë¸ (.pt) ê²½ë¡œ
        onnx_model_path: ONNX ëª¨ë¸ (.onnx) ê²½ë¡œ
    """
    print("=" * 70)
    print("ëª¨ë¸ ë¹„êµ ê²€ì¦")
    print("=" * 70)
    
    # 1. PyTorch ëª¨ë¸ë¡œ ì¶”ë¡ 
    print("\n1ï¸âƒ£ PyTorch ëª¨ë¸ ì¶”ë¡ ")
    print("-" * 70)
    pt_model = YOLO(pt_model_path)
    pt_results = pt_model.predict(
        image_path,
        conf=0.3,
        iou=0.3,
        save=True,
        save_txt=False,
        project="compare_results",
        name="pytorch",
        exist_ok=True
    )
    
    pt_detections = []
    for r in pt_results:
        print(f"âœ… PyTorch ê²€ì¶œ ê°œìˆ˜: {len(r.boxes)}")
        for i, box in enumerate(r.boxes):
            cls = int(box.cls[0])
            conf = float(box.conf[0])
            xyxy = box.xyxy[0].cpu().numpy()
            pt_detections.append({
                'class': cls,
                'confidence': conf,
                'bbox': xyxy
            })
            print(f"   [{i+1}] í´ë˜ìŠ¤: {cls}, ì‹ ë¢°ë„: {conf:.3f}, bbox: {xyxy}")
    
    # 2. ONNX ëª¨ë¸ë¡œ ì¶”ë¡ 
    print("\n2ï¸âƒ£ ONNX ëª¨ë¸ ì¶”ë¡ ")
    print("-" * 70)
    onnx_predictor = YOLOPredictor(onnx_model_path)
    onnx_results = onnx_predictor.predict(
        image_path,
        conf_threshold=0.3,
        iou_threshold=0.3,
        crop_size=640,
        overlap_ratio=0.3,
        visualize=True,
        save_path="compare_results/onnx_result.jpg"
    )
    
    print(f"âœ… ONNX ê²€ì¶œ ê°œìˆ˜: {len(onnx_results)}")
    for i, det in enumerate(onnx_results):
        print(f"   [{i+1}] í´ë˜ìŠ¤: {det['class']}, ì‹ ë¢°ë„: {det['confidence']:.3f}, bbox: {det['bbox']}")
    
    # 3. ë¹„êµ ê²°ê³¼
    print("\n3ï¸âƒ£ ë¹„êµ ê²°ê³¼")
    print("=" * 70)
    print(f"PyTorch ê²€ì¶œ ê°œìˆ˜: {len(pt_detections)}")
    print(f"ONNX ê²€ì¶œ ê°œìˆ˜: {len(onnx_results)}")
    print(f"ì°¨ì´: {abs(len(pt_detections) - len(onnx_results))}ê°œ")
    
    if len(pt_detections) > 0 and len(onnx_results) == 0:
        print("\nâš ï¸ ê²½ê³ : PyTorchëŠ” ê²€ì¶œí–ˆì§€ë§Œ ONNXëŠ” ê²€ì¶œ ì‹¤íŒ¨")
        print("   â†’ ONNX ë³€í™˜ ë˜ëŠ” ì „ì²˜ë¦¬ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    elif len(pt_detections) == 0 and len(onnx_results) == 0:
        print("\nâš ï¸ ê²½ê³ : ë‘ ëª¨ë¸ ëª¨ë‘ ê²€ì¶œ ì‹¤íŒ¨")
        print("   â†’ ëª¨ë¸ ìì²´ì˜ ì„±ëŠ¥ ë˜ëŠ” ì´ë¯¸ì§€ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    elif abs(len(pt_detections) - len(onnx_results)) > 5:
        print("\nâš ï¸ ê²½ê³ : ê²€ì¶œ ê°œìˆ˜ ì°¨ì´ê°€ í½ë‹ˆë‹¤")
        print("   â†’ ONNX ë³€í™˜ ë˜ëŠ” í›„ì²˜ë¦¬ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    else:
        print("\nâœ… ë‘ ëª¨ë¸ì˜ ê²€ì¶œ ê°œìˆ˜ê°€ ë¹„ìŠ·í•©ë‹ˆë‹¤")
    
    # 4. Confidence ë¶„í¬ ë¹„êµ
    if len(pt_detections) > 0:
        print("\n4ï¸âƒ£ Confidence ë¶„í¬")
        print("-" * 70)
        pt_confs = [d['confidence'] for d in pt_detections]
        print(f"PyTorch:")
        print(f"   - í‰ê· : {np.mean(pt_confs):.3f}")
        print(f"   - ìµœëŒ€: {np.max(pt_confs):.3f}")
        print(f"   - ìµœì†Œ: {np.min(pt_confs):.3f}")
        
        if len(onnx_results) > 0:
            onnx_confs = [d['confidence'] for d in onnx_results]
            print(f"ONNX:")
            print(f"   - í‰ê· : {np.mean(onnx_confs):.3f}")
            print(f"   - ìµœëŒ€: {np.max(onnx_confs):.3f}")
            print(f"   - ìµœì†Œ: {np.min(onnx_confs):.3f}")
    
    print("\n" + "=" * 70)
    print(f"ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€:")
    print(f"   - PyTorch: compare_results/pytorch/")
    print(f"   - ONNX: compare_results/onnx_result.jpg")
    print("=" * 70)

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="PyTorch ëª¨ë¸ê³¼ ONNX ëª¨ë¸ ë¹„êµ")
    parser.add_argument("--image", type=str, default="/Users/temp/ë‚´ ë“œë¼ì´ë¸Œ(codejeteho123@gmail.com)/ComputerVision/sample_1920x1080.jpg",
                       help="í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ")
    parser.add_argument("--pt-model", type=str, 
                       default="runs/detect/strawberry_ok_ng/weights/best.pt",
                       help="PyTorch ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--onnx-model", type=str,
                       default="runs/detect/strawberry_ok_ng/weights/best.onnx",
                       help="ONNX ëª¨ë¸ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    compare_models(args.image, args.pt_model, args.onnx_model)

