"""
ë°ì´í„°ì…‹ ì¤€ë¹„ ë° ë³€í™˜
- JSON íŒŒì¼ ìˆ˜ì§‘
- Train/Val ë¶„í• 
- YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜
- ë©€í‹°í”„ë¡œì„¸ì‹± ì§€ì›
"""

import os
import shutil
import random
from pathlib import Path
from tqdm import tqdm
from multiprocessing import Pool, cpu_count

from config import (
    JSON_DIR, IMAGE_DIR, OUTPUT_DIR, CLASS_MAPPING, 
    VAL_RATIO, RANDOM_SEED, CLASS_NAMES, BASE_DIR
)
from utils import json_to_yolo, create_yaml_config


def collect_json_files():
    """JSON íŒŒì¼ ìˆ˜ì§‘ ë° ë§¤í•‘"""
    dataset_info = {}

    for category, class_id in CLASS_MAPPING.items():
        category_dir = JSON_DIR / category
        if category_dir.exists():
            json_files = list(category_dir.glob('*.json'))
            dataset_info[category] = {
                'files': json_files,
                'count': len(json_files),
                'class_id': class_id
            }
            print(f"ğŸ“ {category}: {len(json_files)}ê°œ íŒŒì¼")

    # ëª¨ë“  JSON íŒŒì¼ ìˆ˜ì§‘
    all_json_files = []
    for category, info in dataset_info.items():
        all_json_files.extend([(f, info['class_id']) for f in info['files']])

    return dataset_info, all_json_files


def create_directory_structure():
    """ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
    if OUTPUT_DIR.exists():
        print(f"âš ï¸ ê¸°ì¡´ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì‚­ì œ: {OUTPUT_DIR}")
        shutil.rmtree(OUTPUT_DIR)

    for split in ['train', 'val']:
        (OUTPUT_DIR / 'images' / split).mkdir(parents=True, exist_ok=True)
        (OUTPUT_DIR / 'labels' / split).mkdir(parents=True, exist_ok=True)
    
    print(f"âœ… ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ: {OUTPUT_DIR}")


def process_single_file(args):
    """
    ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ (ë©€í‹°í”„ë¡œì„¸ì‹±ìš©)
    
    Args:
        args: (json_file, class_id, split, image_dir, output_dir) íŠœí”Œ
    
    Returns:
        (ì²˜ë¦¬ ê²°ê³¼, í´ë˜ìŠ¤ ID) íŠœí”Œ
    """
    json_file, class_id, split, image_dir, output_dir = args

    img_filename = json_file.stem + '.jpg'

    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    if class_id == 0:  # ì •ìƒ
        img_src = image_dir / "ì •ìƒ" / img_filename
    else:  # NG
        img_src = image_dir / "NG" / img_filename

    if not img_src.exists():
        return ('fail', class_id)

    # YOLO ë¼ë²¨ ë³€í™˜
    yolo_label = json_to_yolo(json_file, class_id)
    if yolo_label is None:
        return ('fail', class_id)

    # ì´ë¯¸ì§€ ë³µì‚¬
    img_dst = output_dir / 'images' / split / img_filename
    shutil.copy2(img_src, img_dst)

    # ë¼ë²¨ ì €ì¥
    label_dst = output_dir / 'labels' / split / (json_file.stem + '.txt')
    with open(label_dst, 'w') as f:
        f.write(yolo_label)

    return ('success', class_id)


def prepare_dataset(dataset_info, num_workers=None):
    """
    Train/Val ë¶„í•  ë° ë°ì´í„° ë³€í™˜ (CPU ë©€í‹°í”„ë¡œì„¸ì‹±)
    
    Args:
        dataset_info: collect_json_files()ì—ì„œ ë°˜í™˜ëœ ë°ì´í„°ì…‹ ì •ë³´
        num_workers: ì‚¬ìš©í•  ì›Œì»¤ ìˆ˜ (Noneì´ë©´ ìë™ ì„¤ì •)
    
    Returns:
        ì²˜ë¦¬ í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    print("\n" + "=" * 70)
    print("ğŸ”„ ë°ì´í„° ë³€í™˜ ë° ë¶„í•  ì§„í–‰ ì¤‘... (CPU ë©€í‹°í”„ë¡œì„¸ì‹±)")
    print("=" * 70)

    # ì‹œë“œ ì„¤ì •
    random.seed(RANDOM_SEED)

    # í†µê³„ ë³€ìˆ˜
    stats = {
        'train': {'ok': 0, 'ng': 0, 'success': 0, 'fail': 0},
        'val': {'ok': 0, 'ng': 0, 'success': 0, 'fail': 0}
    }

    # CPU ì½”ì–´ ìˆ˜ í™•ì¸
    if num_workers is None:
        num_workers = min(cpu_count(), 8)  # ìµœëŒ€ 8ê°œ í”„ë¡œì„¸ìŠ¤
    print(f"ğŸ’» CPU ì½”ì–´ ìˆ˜: {cpu_count()}ê°œ, ì‚¬ìš©í•  ì›Œì»¤: {num_workers}ê°œ")

    # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì²˜ë¦¬
    for category, info in dataset_info.items():
        print(f"\nì²˜ë¦¬ ì¤‘: {category} ({info['count']}ê°œ)")

        json_files = info['files']
        class_id = info['class_id']

        # ëœë¤ ì…”í”Œ ë° ë¶„í• 
        random.shuffle(json_files)
        split_idx = int(len(json_files) * (1 - VAL_RATIO))

        train_files = json_files[:split_idx]
        val_files = json_files[split_idx:]

        # Train ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬
        train_args = [(f, class_id, 'train', IMAGE_DIR, OUTPUT_DIR) for f in train_files]
        with Pool(num_workers) as pool:
            results = list(tqdm(
                pool.imap(process_single_file, train_args),
                total=len(train_args),
                desc=f"  Train {category}"
            ))

        for result, cid in results:
            if result == 'success':
                stats['train']['success'] += 1
                if cid == 0:
                    stats['train']['ok'] += 1
                else:
                    stats['train']['ng'] += 1
            else:
                stats['train']['fail'] += 1

        # Validation ë°ì´í„° ë³‘ë ¬ ì²˜ë¦¬
        val_args = [(f, class_id, 'val', IMAGE_DIR, OUTPUT_DIR) for f in val_files]
        with Pool(num_workers) as pool:
            results = list(tqdm(
                pool.imap(process_single_file, val_args),
                total=len(val_args),
                desc=f"  Val {category}"
            ))

        for result, cid in results:
            if result == 'success':
                stats['val']['success'] += 1
                if cid == 0:
                    stats['val']['ok'] += 1
                else:
                    stats['val']['ng'] += 1
            else:
                stats['val']['fail'] += 1

    # í†µê³„ ì¶œë ¥
    print("\n" + "=" * 70)
    print("âœ… ë°ì´í„° ë³€í™˜ ì™„ë£Œ!")
    print("=" * 70)
    print(f"\nğŸ“Š Train ë°ì´í„°ì…‹:")
    print(f"   âœ… OK: {stats['train']['ok']}ê°œ")
    print(f"   âŒ NG: {stats['train']['ng']}ê°œ")
    print(f"   ğŸ“ˆ ì´: {stats['train']['success']}ê°œ")
    print(f"   âš ï¸  ì‹¤íŒ¨: {stats['train']['fail']}ê°œ")

    print(f"\nğŸ“Š Validation ë°ì´í„°ì…‹:")
    print(f"   âœ… OK: {stats['val']['ok']}ê°œ")
    print(f"   âŒ NG: {stats['val']['ng']}ê°œ")
    print(f"   ğŸ“ˆ ì´: {stats['val']['success']}ê°œ")
    print(f"   âš ï¸  ì‹¤íŒ¨: {stats['val']['fail']}ê°œ")

    print("\n" + "=" * 70)
    total_success = stats['train']['success'] + stats['val']['success']
    total_fail = stats['train']['fail'] + stats['val']['fail']
    print(f"ğŸ¯ ì „ì²´ ì„±ê³µ: {total_success}ê°œ / ì „ì²´: {total_success + total_fail}ê°œ")
    print(f"âš¡ CPU ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ì•½ {num_workers}ë°° ë¹ ë¥´ê²Œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("=" * 70)

    return stats


def main():
    """ë°ì´í„°ì…‹ ì¤€ë¹„ ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 70)
    print("ğŸ“¦ ë”¸ê¸° OK/NG ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹œì‘")
    print("=" * 70)
    
    # 1. JSON íŒŒì¼ ìˆ˜ì§‘
    print("\n[1/4] JSON íŒŒì¼ ìˆ˜ì§‘ ì¤‘...")
    dataset_info, all_json_files = collect_json_files()
    
    # 2. ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    print("\n[2/4] ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì¤‘...")
    create_directory_structure()
    
    # 3. ë°ì´í„° ë³€í™˜ ë° ë¶„í• 
    print("\n[3/4] ë°ì´í„° ë³€í™˜ ë° ë¶„í•  ì‹œì‘...")
    stats = prepare_dataset(dataset_info)
    
    # 4. YAML ì„¤ì • íŒŒì¼ ìƒì„±
    print("\n[4/4] YAML ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘...")
    yaml_path = BASE_DIR / 'strawberry_ok_ng.yaml'
    create_yaml_config(OUTPUT_DIR, yaml_path, CLASS_NAMES)
    
    print("\n" + "=" * 70)
    print("âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!")
    print("=" * 70)
    
    return stats, yaml_path


if __name__ == "__main__":
    main()

