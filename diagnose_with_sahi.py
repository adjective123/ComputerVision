"""
SAHIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë¶„ë¥˜ë¥¼ ì§„ë‹¨í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction
from sahi.utils.cv import read_image
import cv2
import numpy as np
from pathlib import Path

def diagnose_sahi_predictions(
    model_path: str,
    image_path: str,
    slice_size: int = 640,
    overlap: float = 0.3,
    conf_threshold: float = 0.3
):
    """
    SAHIë¡œ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì˜¤ë¶„ë¥˜ë¥¼ ì§„ë‹¨í•©ë‹ˆë‹¤.
    """
    print("=" * 70)
    print("SAHI ì˜¤ë¶„ë¥˜ ì§„ë‹¨")
    print("=" * 70)
    print(f"\nğŸ“· ì´ë¯¸ì§€: {image_path}")
    print(f"ğŸ¯ ì‹¤ì œ ë¼ë²¨: ëª¨ë“  ë”¸ê¸° = OK")
    print(f"ğŸ” Confidence threshold: {conf_threshold}")
    
    # ëª¨ë¸ ë¡œë“œ
    detection_model = AutoDetectionModel.from_pretrained(
        model_type="yolov8",
        model_path=model_path,
        confidence_threshold=conf_threshold,
        device="cpu"
    )
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = read_image(image_path)
    print(f"   ì´ë¯¸ì§€ í¬ê¸°: {image.shape}")
    
    # ìŠ¬ë¼ì´ìŠ¤ ì˜ˆì¸¡
    result = get_sliced_prediction(
        image,
        detection_model,
        slice_height=slice_size,
        slice_width=slice_size,
        overlap_height_ratio=overlap,
        overlap_width_ratio=overlap,
        postprocess_type="NMS",
        postprocess_match_metric="IOS",
        postprocess_match_threshold=0.5,
        postprocess_class_agnostic=False
    )
    
    # ê²°ê³¼ ë¶„ì„
    ok_detections = []
    ng_detections = []
    
    for pred in result.object_prediction_list:
        class_id = pred.category.id
        class_name = pred.category.name if hasattr(pred.category, 'name') else ("OK" if class_id == 0 else "NG")
        confidence = pred.score.value
        bbox = pred.bbox.to_voc_bbox()
        
        detection = {
            'class_name': class_name,
            'class_id': class_id,
            'confidence': confidence,
            'bbox': bbox,
            'area': (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
        }
        
        if class_id == 0:
            ok_detections.append(detection)
        else:
            ng_detections.append(detection)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š ê²€ì¶œ ê²°ê³¼:")
    print(f"   ì´ ê²€ì¶œ: {len(result.object_prediction_list)}ê°œ")
    print(f"   âœ… OK: {len(ok_detections)}ê°œ (ì •ë‹µ)")
    print(f"   âŒ NG: {len(ng_detections)}ê°œ (ì˜¤ë¶„ë¥˜)")
    
    accuracy = len(ok_detections) / max(len(result.object_prediction_list), 1) * 100
    print(f"\nğŸ“ˆ ì •í™•ë„: {accuracy:.1f}%")
    
    # OK ê²€ì¶œ ìƒì„¸
    if len(ok_detections) > 0:
        print(f"\nâœ… OK ê²€ì¶œ (ì •ë‹µ):")
        ok_confs = [d['confidence'] for d in ok_detections]
        ok_areas = [d['area'] for d in ok_detections]
        for i, det in enumerate(sorted(ok_detections, key=lambda x: -x['confidence'])[:10]):
            print(f"   [{i+1}] ì‹ ë¢°ë„: {det['confidence']:.3f}, ë©´ì : {det['area']:.0f}px")
        print(f"   í‰ê·  ì‹ ë¢°ë„: {np.mean(ok_confs):.3f}")
        print(f"   í‰ê·  ë©´ì : {np.mean(ok_areas):.0f}px")
    
    # NG ê²€ì¶œ ìƒì„¸ (ì˜¤ë¶„ë¥˜)
    if len(ng_detections) > 0:
        print(f"\nâŒ NG ê²€ì¶œ (ì˜¤ë¶„ë¥˜ - ì‹¤ì œë¡œëŠ” OK):")
        ng_confs = [d['confidence'] for d in ng_detections]
        ng_areas = [d['area'] for d in ng_detections]
        for i, det in enumerate(sorted(ng_detections, key=lambda x: -x['confidence'])[:10]):
            print(f"   [{i+1}] ì‹ ë¢°ë„: {det['confidence']:.3f}, ë©´ì : {det['area']:.0f}px")
        print(f"   í‰ê·  ì‹ ë¢°ë„: {np.mean(ng_confs):.3f}")
        print(f"   í‰ê·  ë©´ì : {np.mean(ng_areas):.0f}px")
    
    # ê°œë³„ ê²€ì¶œ ì´ë¯¸ì§€ ì €ì¥
    save_detection_crops(image_path, ok_detections, ng_detections)
    
    # ë¶„ì„
    print("\n" + "=" * 70)
    print("ğŸ”¬ ë¶„ì„")
    print("=" * 70)
    
    if len(ok_detections) > 0 and len(ng_detections) > 0:
        ok_avg_conf = np.mean([d['confidence'] for d in ok_detections])
        ng_avg_conf = np.mean([d['confidence'] for d in ng_detections])
        
        print(f"\nì‹ ë¢°ë„ ë¹„êµ:")
        print(f"   OK (ì •ë‹µ): {ok_avg_conf:.3f}")
        print(f"   NG (ì˜¤ë¶„ë¥˜): {ng_avg_conf:.3f}")
        
        if ng_avg_conf < ok_avg_conf:
            print(f"   â†’ NGì˜ ì‹ ë¢°ë„ê°€ ë” ë‚®ìŒ: Thresholdë¥¼ {ng_avg_conf:.2f} ì´ìƒìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì˜¤ë¶„ë¥˜ ê°ì†Œ")
        else:
            print(f"   â†’ NGì˜ ì‹ ë¢°ë„ê°€ ë†’ìŒ: ëª¨ë¸ ì¬í•™ìŠµ í•„ìš”")
    
    # ê¶Œì¥ì‚¬í•­
    print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    if len(ng_detections) > len(ok_detections):
        print("   âš ï¸ ì˜¤ë¶„ë¥˜ê°€ ì •ë‹µë³´ë‹¤ ë§ìŒ - ì‹¬ê°í•œ ë¬¸ì œ!")
        print("   1. í•™ìŠµ ë°ì´í„°ì˜ ë¼ë²¨ í™•ì¸")
        print("   2. OK/NG ê¸°ì¤€ ì¬ì •ì˜")
        print("   3. ëª¨ë¸ ì¬í•™ìŠµ í•„ìš”")
    elif len(ng_detections) > 0:
        # NG ì¤‘ ìµœì†Œ ì‹ ë¢°ë„ ì°¾ê¸°
        min_ng_conf = min([d['confidence'] for d in ng_detections])
        print(f"   1. Confidence thresholdë¥¼ {min_ng_conf:.2f} ì´ìƒìœ¼ë¡œ ì„¤ì •")
        print(f"      python test_sahi.py --conf {min_ng_conf:.2f}")
        print(f"   2. ë˜ëŠ” ëª¨ë¸ ì¬í•™ìŠµìœ¼ë¡œ OK/NG êµ¬ë¶„ë ¥ í–¥ìƒ")
    else:
        print("   âœ… ì˜¤ë¶„ë¥˜ ì—†ìŒ - ëª¨ë¸ ì„±ëŠ¥ ì–‘í˜¸!")
    
    print("=" * 70)
    
    return ok_detections, ng_detections


def save_detection_crops(image_path: str, ok_detections: list, ng_detections: list):
    """
    ê²€ì¶œëœ ì˜ì—­ì„ ê°œë³„ ì´ë¯¸ì§€ë¡œ ì €ì¥
    """
    image = cv2.imread(image_path)
    output_dir = Path("detection_crops")
    output_dir.mkdir(exist_ok=True)
    
    print(f"\nğŸ’¾ ê²€ì¶œ ì˜ì—­ ì €ì¥: {output_dir}/")
    
    # OK ì €ì¥
    for i, det in enumerate(ok_detections[:10]):  # ìµœëŒ€ 10ê°œ
        x1, y1, x2, y2 = map(int, det['bbox'])
        crop = image[y1:y2, x1:x2]
        if crop.size > 0:
            filename = f"OK_{i+1}_conf{det['confidence']:.3f}.jpg"
            cv2.imwrite(str(output_dir / filename), crop)
    
    # NG ì €ì¥ (ì˜¤ë¶„ë¥˜)
    for i, det in enumerate(ng_detections[:10]):  # ìµœëŒ€ 10ê°œ
        x1, y1, x2, y2 = map(int, det['bbox'])
        crop = image[y1:y2, x1:x2]
        if crop.size > 0:
            filename = f"NG_WRONG_{i+1}_conf{det['confidence']:.3f}.jpg"
            cv2.imwrite(str(output_dir / filename), crop)
    
    print(f"   âœ“ OK (ì •ë‹µ): {min(len(ok_detections), 10)}ê°œ")
    print(f"   âœ“ NG (ì˜¤ë¶„ë¥˜): {min(len(ng_detections), 10)}ê°œ")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="SAHI ì˜¤ë¶„ë¥˜ ì§„ë‹¨")
    parser.add_argument("--model", type=str,
                       default="runs/detect/strawberry_ok_ng/weights/best.pt",
                       help="ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--image", type=str,
                       default="sample.jpg",
                       help="ì „ë¶€ OKì¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€")
    parser.add_argument("--slice-size", type=int, default=640,
                       help="ìŠ¬ë¼ì´ìŠ¤ í¬ê¸°")
    parser.add_argument("--overlap", type=float, default=0.3,
                       help="ì˜¤ë²„ë© ë¹„ìœ¨")
    parser.add_argument("--conf", type=float, default=0.3,
                       help="Confidence threshold")
    
    args = parser.parse_args()
    
    ok_dets, ng_dets = diagnose_sahi_predictions(
        args.model,
        args.image,
        args.slice_size,
        args.overlap,
        args.conf
    )

